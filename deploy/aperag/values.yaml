# Default values for aperag.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.


image:
  repository: "aperag"  # Full image name including registry
  tag: "latest"
  pullPolicy: IfNotPresent

  paddleocr:
    repository: "docker.io/gswyhq/paddleocr"  # Full image name including registry
    tag: "hubserving"
  whisper:
    repository: "docker.io/onerahmet/openai-whisper-asr-webservice"  # Full image name including registry
    tag: "latest-gpu"
  embedding:
    repository: "docker.io/michaelf34/infinity"  # Full image name including registry
    tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}


ingress:
  className: ""
  annotations: {}

django:
  logLevel: INFO
  dataPath: /data/aperag
  replicaCount: 1
  feishu:
    appID: ""
    appSecret: ""
    encryptKey: ""
  quota:
    maxBotCount: 10
    maxCollectionCount: 50
    maxDocumentCount: 1000
    maxConversationCount: 100
  resources:
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  authType: none
  esHost: http://elasticsearch-mdit-http:9200
  redisSecret: redis-redis-account-default
  redisHost: redis-redis-redis
  redisPort: 6379
  redisUsername: default
  redisPassword: password
  metaDBSecret: postgresql-conn-credential
  metaDBDatabase: aperag
  metaDBHost: aperag-postgres
  metaDBPort: 5432
  metaDBUsername: postgres
  metaDBPassword: postgres
  adminUser: ""
  adminToken: ""
  vectorDBType: qdrant
  vectorDBContext: '{"url":"http://qdrant-qdrant", "port":6333, "distance":"Cosine", "timeout": 1000}'
  objectStoreType: local
  objectStoreLocalRootDir: /data/objects
  # S3 object store settings (when objectStoreType is s3)
  objectStoreS3Endpoint: ""
  objectStoreS3Region: ""
  objectStoreS3AccessKey: ""
  objectStoreS3SecretKey: ""
  objectStoreS3Bucket: aperag
  objectStoreS3PrefixPath: ""
  objectStoreS3UsePathStyle: "True"
  # Chunking settings
  chunkSize: 400
  chunkOverlapSize: 20
  embeddingMaxChunksInBatch: 16
  # Email settings
  emailHost: smtp.gmail.com
  emailPort: 587
  emailUseTls: "True"
  emailHostUser: ""
  emailHostPassword: ""
  defaultFromEmail: noreply@aperag.com
  siteUrl: http://localhost:8000
  # Registration
  registerMode: unlimited
  # Chat
  chatConsumerImplementation: document-qa
  # Rerank settings
  rerankServiceModel: "jina-reranker-v2-base-multilingual"
  rerankServiceTokenApiKey: ""
  openaiAPIKey: ""
  openaiProxy: ""
  openaiAPIBase: ""
  azureOpenAIDeploymentName: ""
  azureOpenAIAPIKey: ""
  azureOpenAIAPIBase: ""
  azureOpenAIAPIVersion: ""
  embeddingModel: "bge"
  embeddingDevice: "cpu"
  whisperHost: http://openai-whisper-asr-service:9000
  paddleocrHost: http://paddleocr-hubserving-service:8866
  embeddingBackend: "xinference"
  embeddingServiceUrl: http://xinference-xinference:9997
  embeddingServiceModel: "bge-large-zh-v1.5"
  embeddingServiceModelUid: ""
  rerankBackend: "jina_ai"
  rerankServiceUrl: https://api.jina.ai/v1/rerank
  rerankServiceModelUid: ""
  # django must be co-located with celery-worker in order to handle uploaded documents
  affinity:
    podAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchLabels:
              app.aperag.io/component: celery-worker
          topologyKey: kubernetes.io/hostname
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app.aperag.io/component: django
            topologyKey: kubernetes.io/hostname
  modelFamilies:
    - name: "qianwen"
      label: "QianWen"
      enabled: "true"
      temperature: 0.01
      models:
        - name: "qwen-turbo"
          label: "QianWen Turbo"
          enabled: "true"
          memory: "enabled"
          # https://help.aliyun.com/zh/dashscope/developer-reference/api-details?spm=a2c4g.11186623.0.i54
          context_window: 8096
        - name: "qwen-plus"
          label: "QianWen Plus"
          enabled: "true"
          memory: "enabled"
          # https://help.aliyun.com/zh/dashscope/developer-reference/api-details?spm=a2c4g.11186623.0.i54
          context_window: 8096
        - name: "qwen-max"
          label: "QianWen Max"
          enabled: "true"
          memory: "enabled"
          # https://help.aliyun.com/zh/dashscope/developer-reference/api-details?spm=a2c4g.11186623.0.i54
          context_window: 8096
    - name: "azure-openai"
      label: "Azure OpenAI"
      enabled: "true"
      temperature: 0
      models:
        - name: "azure-openai"
          label: "Azure OpenAI"
          enabled: "true"
          memory: "enabled"
          # https://learn.microsoft.com/zh-cn/azure/ai-services/openai/reference
          context_window: 4096
          free_tier: true
    - name: "chatgpt"
      label: "ChatGPT"
      enabled: "true"
      temperature: 0
      models:
        - name: "gpt-4"
          label: "ChatGPT-4"
          enabled: "true"
          memory: "enabled"
          # https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo
          context_window: 8192
    - name: "deepseek"
      label: "DeepSeek"
      enabled: "true"
      models:
      - name: "deepseek-chat"
        label: "DeepSeek Chat"
        enabled: "true"
        memory: "disabled"
        free_tier: true
        context_window: 128000
        similarity_topk: 10
    - name: "glm-4"
      label: "GLM-4"
      enabled: "true"
      models:
        - name: "glm-4-plus"
          label: "GLM-4-Plus"
          enabled: "true"
          memory: "enabled"
          context_window: 128000
          similarity_topk: 10
          endpoint: "https://open.bigmodel.cn/api/paas/v4/"
        - name: "glm-4-air"
          label: "GLM-4-Air"
          enabled: "true"
          memory: "enabled"
          context_window: 128000
          similarity_topk: 10
          endpoint: "https://open.bigmodel.cn/api/paas/v4/"
        - name: "glm-4-long"
          label: "GLM-4-Long"
          enabled: "true"
          memory: "enabled"
          context_window: 1000000
          similarity_topk: 20
          endpoint: "https://open.bigmodel.cn/api/paas/v4/"
        - name: "glm-4-flashx"
          label: "GLM-4-FlashX"
          enabled: "true"
          memory: "enabled"
          context_window: 128000
          similarity_topk: 10
          endpoint: "https://open.bigmodel.cn/api/paas/v4/"
        - name: "glm-4-flash"
          label: "GLM-4-Flash"
          enabled: "true"
          memory: "enabled"
          context_window: 128000
          similarity_topk: 10
          endpoint: "https://open.bigmodel.cn/api/paas/v4/"
          free_tier: true

celery-worker:
  replicaCount: 1
  embeddingDevice: "cpu"
  resources: { }
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        podAffinityTerm:
          labelSelector:
            matchLabels:
              app.aperag.io/component: celery-worker
          topologyKey: kubernetes.io/hostname

celery-beat:
  replicaCount: 1
  resources: { }
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

flower:
  replicaCount: 1
  user: admin
  password: admin
  resources: { }
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

whisper:
  enabled: false
  replicaCount: 1
  resources:
    limits:
      nvidia.com/gpu: "1"
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

paddleocr:
  enabled: false
  replicaCount: 1
  resources:
    limits:
      nvidia.com/gpu: "1"
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

# Frontend configuration
frontend:
  replicaCount: 1
  image:
    repository: "aperag-frontend"  # Full image name including registry
    tag: "latest"
    pullPolicy: IfNotPresent
  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 50m
    #   memory: 64Mi
  affinity: {}
  # Frontend configuration values for settings.js
  title: "ApeRAG"
  favicon: ""
  logoDark: ""
  logoLight: ""
  github: "https://github.com/apecloud/ApeRAG"
  publicIps: []
