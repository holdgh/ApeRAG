import json
import uuid
import re
from abc import ABC, abstractmethod
from typing import Dict, List, Optional

from langchain import PromptTemplate
from langchain.schema import AIMessage, HumanMessage
from pydantic import BaseModel

from kubechat.chat.history.base import BaseChatMessageHistory
from kubechat.llm.base import Predictor, PredictorType
from kubechat.llm.prompts import RELATED_QUESTIONS_TEMPLATE_V2
from kubechat.utils.utils import now_unix_milliseconds


class Message(BaseModel):
    id: str
    query: Optional[str]
    timestamp: Optional[int]
    response: Optional[str]
    references: Optional[List[Dict]]
    collection_id: Optional[str]
    embedding_model: Optional[str]
    embedding_size: Optional[int]
    embedding_score_threshold: Optional[float]
    embedding_topk: Optional[int]
    llm_model: Optional[str]
    llm_prompt_template: Optional[str]
    llm_context_window: Optional[int]


KUBE_CHAT_DOC_QA_REFERENCES = "|KUBE_CHAT_DOC_QA_REFERENCES|"
KUBE_CHAT_RELATED_QUESTIONS = "|KUBE_CHAT_RELATED_QUESTIONS|"


class Pipeline(ABC):
    def __init__(self,
                 bot,
                 collection,
                 history: BaseChatMessageHistory,
                 ):
        self.bot = bot
        self.collection = collection
        self.history = history
        bot_config = json.loads(self.bot.config)
        self.llm_config = bot_config.get("llm", {})
        self.model = bot_config.get("model", "baichuan-13b")
        self.memory = bot_config.get("memory", False)
        self.memory_count = 0
        self.memory_limit_length = bot_config.get("memory_length", 0)
        self.memory_limit_count = bot_config.get("memory_count", 10)
        self.use_ai_memory = bot_config.get("use_ai_memory", True)
        self.topk = self.llm_config.get("similarity_topk", 3)
        self.enable_keyword_recall = self.llm_config.get("enable_keyword_recall", False)
        self.score_threshold = self.llm_config.get("similarity_score_threshold", 0.5)
        self.context_window = self.llm_config.get("context_window", 3500)
        self.use_related_question = bot_config.get("use_related_question", False)
        self.bot_context = ""

        welcome = bot_config.get("welcome", {})
        faq = welcome.get("faq", [])
        self.welcome_question = []
        for qa in faq:
            self.welcome_question.append(qa["question"])
        self.oops = welcome.get("oops", "")

        self.prompt_template = self.llm_config.get("prompt_template", None)

        kwargs = {"model": self.model}
        kwargs.update(self.llm_config)
        self.predictor = Predictor.from_model(self.model, PredictorType.CUSTOM_LLM, **kwargs)

        if self.use_related_question:
            self.related_prompt_template = self.llm_config.get("related_prompt_template", RELATED_QUESTIONS_TEMPLATE_V2)
            self.related_question_prompt = PromptTemplate(template=self.related_prompt_template,
                                                          input_variables=["query", "context"])
            kwargs = {"model": "gpt-4-0125-preview"}
            self.related_question_predictor = Predictor.from_model("gpt-4", **kwargs)

    async def generate_related_question(self, related_question_prompt):
        tools = [
            {
                "type": "function",
                "function": {
                    "name": "ask_related_questions",
                    "description": "ask further questions that are related to the input and output.",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "question": {
                                "type": "string",
                                "description": "related question to the original question and context.",
                            },
                        },
                        "required": ["question"],
                    },
                },
            }
        ]
        related_questions = []
        tool_responses, content = await self.related_question_predictor.agenerate_by_tools(related_question_prompt, tools)
        if tool_responses:
            for tool_response in tool_responses:
                if tool_response.function.name == "ask_related_questions":
                    function_args = json.loads(tool_response.function.arguments)
                    question = function_args.get("question")
                    if question:
                        related_questions.append(question)
        else:
            related_questions = [] 
            if content=='':
                return related_questions
            questions = re.sub(r'\n+', '\n', content).split('\n')
            for question in questions:
                match = re.match(r"\s*-\s*(.*)", question)
                if match:
                    question = match.group(1)
                match = re.match(r"\s*\d+\.\s*(.*)", question)
                if match:
                    question = match.group(1)
                related_questions.append(question)
        return related_questions
    
    @staticmethod
    async def new_human_message(message, message_id):
        return Message(
            id=message_id,
            query=message,
            timestamp=now_unix_milliseconds(),
        )

    async def new_ai_message(self, message, message_id, response, references):
        pass

    async def add_human_message(self, message, message_id):
        if not message_id:
            message_id = str(uuid.uuid4())

        human_msg = await (self.new_human_message(message, message_id))
        human_msg = human_msg.json(exclude_none=True)
        await self.history.add_message(
            HumanMessage(
                content=human_msg,
                additional_kwargs={"role": "human"}
            )
        )

    async def add_ai_message(self, message, message_id, response, references):
        ai_msg = await (self.new_ai_message(message, message_id, response, references))
        ai_msg = ai_msg.json(exclude_none=True)
        await self.history.add_message(
            AIMessage(
                content=ai_msg,
                additional_kwargs={"role": "ai"}
            )
        )

    @abstractmethod
    async def run(self, query, gen_references=False, message_id=""):
        pass

    async def update_bot_context(self, bot_context):
        self.bot_context = bot_context