# ApeRAG WebSearch æ¨¡å—

## æ¦‚è¿°

ApeRAG WebSearchæ¨¡å—æä¾›ç»Ÿä¸€çš„Webæœç´¢å’Œå†…å®¹è¯»å–èƒ½åŠ›ï¼Œæ”¯æŒå¤šç§æœç´¢å¼•æ“å’Œå†…å®¹æå–å™¨ã€‚æ¨¡å—é‡‡ç”¨Provideræ¨¡å¼è®¾è®¡ï¼Œæ˜“äºæ‰©å±•å’Œç»´æŠ¤ã€‚

## æ¶æ„è®¾è®¡

```
aperag/websearch/
â”œâ”€â”€ search/                     # æœç´¢åŠŸèƒ½
â”‚   â”œâ”€â”€ base_search.py         # æœç´¢åŸºç±»
â”‚   â”œâ”€â”€ search_service.py      # æœç´¢æœåŠ¡
â”‚   â””â”€â”€ providers/             # æœç´¢æä¾›å•†
â”‚       â”œâ”€â”€ duckduckgo_search_provider.py
â”‚       â””â”€â”€ jina_search_provider.py
â”œâ”€â”€ reader/                     # å†…å®¹è¯»å–åŠŸèƒ½
â”‚   â”œâ”€â”€ base_reader.py         # è¯»å–åŸºç±»
â”‚   â”œâ”€â”€ reader_service.py      # è¯»å–æœåŠ¡
â”‚   â””â”€â”€ providers/             # è¯»å–æä¾›å•†
â”‚       â”œâ”€â”€ trafilatura_read_provider.py
â”‚       â””â”€â”€ jina_read_provider.py
â””â”€â”€ utils/                      # å·¥å…·æ¨¡å—
    â”œâ”€â”€ url_validator.py       # URLéªŒè¯
    â””â”€â”€ content_processor.py   # å†…å®¹å¤„ç†
```

## Search Providers

### 1. DuckDuckGoProvider

åŸºäºDuckDuckGoæœç´¢å¼•æ“çš„æœç´¢providerï¼Œå…è´¹ä¸”æ— éœ€APIå¯†é’¥ã€‚

#### ç‰¹ç‚¹
- âœ… å…è´¹ä½¿ç”¨ï¼Œæ— éœ€é…ç½®
- âœ… æ”¯æŒå¤šè¯­è¨€æœç´¢
- âœ… éšç§å‹å¥½ï¼Œä¸è¿½è¸ªç”¨æˆ·
- âœ… ç»“æœè´¨é‡ç¨³å®š

#### åŸºç¡€ç”¨æ³•

```python
from aperag.websearch.search.search_service import SearchService

# åˆ›å»ºæœç´¢æœåŠ¡ï¼ˆé»˜è®¤ä½¿ç”¨DuckDuckGoï¼‰
search_service = SearchService()

# æˆ–æ˜¾å¼æŒ‡å®šDuckDuckGo
search_service = SearchService(provider_name="duckduckgo")

# æ‰§è¡Œæœç´¢
request = WebSearchRequest(
    query="ApeRAG RAGç³»ç»Ÿ",
    max_results=5
)

response = await search_service.search(request)
for result in response.results:
    print(f"æ ‡é¢˜: {result.title}")
    print(f"URL: {result.url}")
    print(f"æ‘˜è¦: {result.snippet}")
```

#### é…ç½®é€‰é¡¹

```python
# DuckDuckGoæ— éœ€ç‰¹æ®Šé…ç½®ï¼Œæ”¯æŒçš„å‚æ•°åŒ…æ‹¬ï¼š
request = WebSearchRequest(
    query="æœç´¢å…³é”®è¯",
    max_results=10,        # æœ€å¤§ç»“æœæ•°é‡
    locale="zh-CN",       # æœç´¢è¯­è¨€
    timeout=30            # è¯·æ±‚è¶…æ—¶æ—¶é—´
)
```

### 2. JinaSearchProvider

åŸºäºJINA AIçš„LLMä¼˜åŒ–æœç´¢providerï¼Œä¸“ä¸ºAIåº”ç”¨è®¾è®¡ã€‚

#### ç‰¹ç‚¹
- ğŸš€ LLMä¼˜åŒ–çš„æœç´¢ç»“æœ
- ğŸ” æ”¯æŒå¤šæœç´¢å¼•æ“ï¼ˆGoogleã€Bingï¼‰
- ğŸ“Š æä¾›å¼•ç”¨ä¿¡æ¯å’Œç›¸å…³æ€§è¯„åˆ†
- ğŸŒ æ”¯æŒå¤šè¯­è¨€å’Œåœ°åŒºå®šåˆ¶
- âš¡ ä¸“ä¸ºAI Agentè®¾è®¡

#### åŸºç¡€ç”¨æ³•

```python
from aperag.websearch.search.search_service import SearchService

# åˆ›å»ºJINAæœç´¢æœåŠ¡
search_service = SearchService(
    provider_name="jina",
    provider_config={
        "api_key": "your_jina_api_key"
    }
)

# æ‰§è¡Œæœç´¢
request = WebSearchRequest(
    query="ApeRAGæ¶æ„è®¾è®¡",
    max_results=5,
    search_engine="google",  # æˆ– "bing", "jina"
    locale="zh-CN"
)

response = await search_service.search(request)
for result in response.results:
    print(f"æ ‡é¢˜: {result.title}")
    print(f"URL: {result.url}")
    print(f"æ‘˜è¦: {result.snippet}")
    print(f"åŸŸå: {result.domain}")
```

#### é«˜çº§ç‰¹æ€§

```python
# JINAæœç´¢ä½¿ç”¨æ ‡å‡†çš„WebSearchRequestæ¥å£
# é«˜çº§ç‰¹æ€§ï¼ˆå¼•ç”¨ä¿¡æ¯ã€å›¾ç‰‡ã€æ—¶é—´èŒƒå›´ç­‰ï¼‰åœ¨providerå†…éƒ¨è‡ªåŠ¨å¤„ç†
request = WebSearchRequest(
    query="æœºå™¨å­¦ä¹ æœ€æ–°å‘å±•",
    max_results=10,
    search_engine="google",      # æ”¯æŒ: "google", "bing", "jina"
    locale="zh-CN",             # è¯­è¨€åœ°åŒº
    timeout=30                  # è¶…æ—¶æ—¶é—´
)

# JINA providerå†…éƒ¨è‡ªåŠ¨å¯ç”¨ä»¥ä¸‹ç‰¹æ€§ï¼š
# - å¼•ç”¨ä¿¡æ¯æå– (include_citations=True)
# - LLMä¼˜åŒ–çš„ç»“æœæ ¼å¼
# - ç›¸å…³æ€§è¯„åˆ†
# - æ™ºèƒ½å†…å®¹æ‘˜è¦
```

#### æ”¯æŒçš„æœç´¢å¼•æ“

```python
# è·å–æ”¯æŒçš„æœç´¢å¼•æ“åˆ—è¡¨
engines = search_service.get_supported_engines()
print(engines)  # ['jina', 'google', 'bing']
```

## Reader Providers

### 1. TrafilaturaProvider

åŸºäºTrafilaturaåº“çš„å†…å®¹æå–å™¨ï¼Œå¿«é€Ÿé«˜æ•ˆçš„æœ¬åœ°å¤„ç†ã€‚

#### ç‰¹ç‚¹
- âš¡ é«˜æ€§èƒ½æœ¬åœ°å¤„ç†
- ğŸ¯ å‡†ç¡®çš„æ­£æ–‡æå–
- ğŸ“± æ”¯æŒå¤šç§ç½‘é¡µæ ¼å¼
- ğŸ”§ å¯è‡ªå®šä¹‰æå–è§„åˆ™
- ğŸ’° å®Œå…¨å…è´¹

#### åŸºç¡€ç”¨æ³•

```python
from aperag.websearch.reader.reader_service import ReaderService

# åˆ›å»ºè¯»å–æœåŠ¡ï¼ˆé»˜è®¤ä½¿ç”¨Trafilaturaï¼‰
reader_service = ReaderService()

# æˆ–æ˜¾å¼æŒ‡å®šTrafilatura
reader_service = ReaderService(provider_name="trafilatura")

# è¯»å–å•ä¸ªURL
request = WebReadRequest(
    urls="https://example.com/article"
)

response = await reader_service.read(request)
for result in response.results:
    if result.status == "success":
        print(f"æ ‡é¢˜: {result.title}")
        print(f"å†…å®¹: {result.content}")
        print(f"å­—æ•°: {result.word_count}")
```

#### æ‰¹é‡å¤„ç†

```python
# æ‰¹é‡è¯»å–å¤šä¸ªURL
request = WebReadRequest(
    urls=[
        "https://example.com/article1",
        "https://example.com/article2",
        "https://example.com/article3"
    ],
    max_concurrent=3,  # æœ€å¤§å¹¶å‘æ•°
    timeout=30
)

response = await reader_service.read(request)
print(f"æˆåŠŸ: {response.successful}/{response.total_urls}")

for result in response.results:
    if result.status == "success":
        print(f"âœ… {result.url}: {result.title}")
    else:
        print(f"âŒ {result.url}: {result.error}")
```

### 2. JinaReaderProvider

åŸºäºJINA AIçš„LLMä¼˜åŒ–å†…å®¹æå–å™¨ï¼Œä¸“ä¸ºAIåº”ç”¨ä¼˜åŒ–ã€‚

#### ç‰¹ç‚¹
- ğŸ¤– LLMä¼˜åŒ–çš„å†…å®¹æå–
- ğŸ“ Markdownæ ¼å¼è¾“å‡º
- ğŸ¯ æ™ºèƒ½CSSé€‰æ‹©å™¨æ”¯æŒ
- ğŸ”„ SPAé¡µé¢æ”¯æŒ
- ğŸ“Š è¯¦ç»†çš„å…ƒæ•°æ®ä¿¡æ¯

#### åŸºç¡€ç”¨æ³•

```python
from aperag.websearch.reader.reader_service import ReaderService

# åˆ›å»ºJINAè¯»å–æœåŠ¡
reader_service = ReaderService(
    provider_name="jina",
    provider_config={
        "api_key": "your_jina_api_key"
    }
)

# è¯»å–ç½‘é¡µå†…å®¹
request = WebReadRequest(
    urls="https://example.com/article",
    timeout=30,                # è¯·æ±‚è¶…æ—¶æ—¶é—´
    locale="zh-CN"             # è¯­è¨€åœ°åŒº
)

response = await reader_service.read(request)
for result in response.results:
    print(f"æ ‡é¢˜: {result.title}")
    print(f"å†…å®¹: {result.content}")  # Markdownæ ¼å¼
    print(f"Tokenæ•°: {result.token_count}")
```

#### é«˜çº§ç‰¹æ€§

```python
# JINAè¯»å–æœåŠ¡ä½¿ç”¨æ ‡å‡†çš„WebReadRequestæ¥å£
# é«˜çº§ç‰¹æ€§ï¼ˆCSSé€‰æ‹©å™¨ã€SPAæ”¯æŒã€ç¼“å­˜æ§åˆ¶ç­‰ï¼‰åœ¨providerå†…éƒ¨è‡ªåŠ¨å¤„ç†
request = WebReadRequest(
    urls="https://news.example.com/article",
    timeout=45,                # é€‚å½“å¢åŠ è¶…æ—¶ç”¨äºå¤æ‚é¡µé¢
    locale="zh-CN",           # è¯­è¨€åœ°åŒº
    max_concurrent=2          # æ§åˆ¶å¹¶å‘æ•°
)

response = await reader_service.read(request)
result = response.results[0]

if result.status == "success":
    print(f"æ ‡é¢˜: {result.title}")
    print(f"å†…å®¹: {result.content}")  # å·²ä¼˜åŒ–çš„Markdownæ ¼å¼
    print(f"å­—æ•°: {result.word_count}")
    print(f"Tokenæ•°: {result.token_count}")

# JINA providerå†…éƒ¨è‡ªåŠ¨å¯ç”¨ä»¥ä¸‹ç‰¹æ€§ï¼š
# - æ™ºèƒ½å†…å®¹æå– (target_selectorè‡ªåŠ¨è¯†åˆ«)
# - å¹¿å‘Šå’Œæ— å…³å†…å®¹è¿‡æ»¤ (exclude_selectorè‡ªåŠ¨å¤„ç†)
# - SPAé¡µé¢æ”¯æŒ (wait_for_selectorè‡ªåŠ¨å¤„ç†)
# - LLMä¼˜åŒ–çš„Markdownè¾“å‡º
# - å…ƒæ•°æ®å’Œç»“æ„åŒ–ä¿¡æ¯æå–
```

## æœåŠ¡ä½¿ç”¨æŒ‡å—

### ç»Ÿä¸€çš„æœåŠ¡æ¥å£

SearchServiceå’ŒReaderServiceéƒ½æä¾›ç»Ÿä¸€çš„æ¥å£ï¼Œä¾¿äºåœ¨ä¸åŒprovideré—´åˆ‡æ¢ï¼š

```python
# æœç´¢æœåŠ¡ç¤ºä¾‹
from aperag.websearch.search.search_service import SearchService

# æ–¹å¼1ï¼šä½¿ç”¨é»˜è®¤provider
service = SearchService()

# æ–¹å¼2ï¼šæŒ‡å®šprovideråç§°
service = SearchService(provider_name="jina")

# æ–¹å¼3ï¼šæŒ‡å®šproviderå’Œé…ç½®
service = SearchService(
    provider_name="jina",
    provider_config={"api_key": "your_key"}
)

# è·å–å½“å‰providerä¿¡æ¯
print(f"å½“å‰provider: {service.provider_name}")
```

### é”™è¯¯å¤„ç†

```python
# é”™è¯¯ç±»ä»å…·ä½“providerå¯¼å…¥
from aperag.websearch.search.providers.duckduckgo_search_provider import SearchProviderError
from aperag.websearch.reader.providers.trafilatura_read_provider import ReaderProviderError

try:
    response = await search_service.search(request)
except SearchProviderError as e:
    print(f"æœç´¢å¤±è´¥: {e}")
except Exception as e:
    print(f"æœªçŸ¥é”™è¯¯: {e}")

try:
    response = await reader_service.read(request)
    for result in response.results:
        if result.status == "error":
            print(f"è¯»å–å¤±è´¥ {result.url}: {result.error}")
except ReaderProviderError as e:
    print(f"è¯»å–æœåŠ¡å¤±è´¥: {e}")

# å¯¹äºJINA providersï¼Œå¯ä»¥å¯¼å…¥å¯¹åº”çš„é”™è¯¯ç±»
# from aperag.websearch.search.providers.jina_search_provider import SearchProviderError
# from aperag.websearch.reader.providers.jina_read_provider import ReaderProviderError
```

### å¼‚æ­¥æ‰¹å¤„ç†

```python
import asyncio

async def batch_search_and_read():
    """æ‰¹é‡æœç´¢å¹¶è¯»å–å†…å®¹çš„å®Œæ•´ç¤ºä¾‹"""
    
    # åˆå§‹åŒ–æœåŠ¡
    search_service = SearchService(provider_name="jina", 
                                 provider_config={"api_key": "your_key"})
    reader_service = ReaderService(provider_name="jina",
                                 provider_config={"api_key": "your_key"})
    
    # 1. æ‰§è¡Œæœç´¢
    search_request = WebSearchRequest(
        query="ApeRAG RAGç³»ç»Ÿæ¶æ„",
        max_results=5
    )
    
    search_response = await search_service.search(search_request)
    urls = [result.url for result in search_response.results]
    
    # 2. æ‰¹é‡è¯»å–å†…å®¹
    read_request = WebReadRequest(
        urls=urls,
        max_concurrent=3
    )
    
    read_response = await reader_service.read(read_request)
    
    # 3. æ•´åˆç»“æœ
    for i, search_result in enumerate(search_response.results):
        read_result = read_response.results[i]
        
        print(f"\n=== {search_result.title} ===")
        print(f"URL: {search_result.url}")
        print(f"æœç´¢æ‘˜è¦: {search_result.snippet}")
        
        if read_result.status == "success":
            print(f"å®Œæ•´å†…å®¹: {read_result.content[:200]}...")
            print(f"å­—æ•°: {read_result.word_count}")
        else:
            print(f"å†…å®¹è¯»å–å¤±è´¥: {read_result.error}")

# è¿è¡Œç¤ºä¾‹
asyncio.run(batch_search_and_read())
```

## é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰

è™½ç„¶æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼Œä½†æ¨èç›´æ¥åœ¨ä»£ç ä¸­ä¼ é€’é…ç½®ï¼š

```bash
# .env æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
JINA_API_KEY=your_jina_api_key_here
```

### æ¨èé…ç½®æ–¹å¼

```python
# æ¨èï¼šç›´æ¥ä¼ é€’é…ç½®å‚æ•°
config = {
    "api_key": "your_jina_api_key",
    "timeout": 30,
    "max_retries": 3
}

service = SearchService(provider_name="jina", provider_config=config)
```

## æœ€ä½³å®è·µ

### 1. Provideré€‰æ‹©å»ºè®®

**æœç´¢Provideré€‰æ‹©:**
- **DuckDuckGo**: é€‚ç”¨äºç®€å•æœç´¢éœ€æ±‚ï¼Œå…è´¹ç¨³å®š
- **JINA**: é€‚ç”¨äºAIåº”ç”¨ï¼Œéœ€è¦é«˜è´¨é‡ç»“æœå’Œå¼•ç”¨ä¿¡æ¯

**è¯»å–Provideré€‰æ‹©:**
- **Trafilatura**: é€‚ç”¨äºå¤§é‡æœ¬åœ°å¤„ç†ï¼Œé«˜æ€§èƒ½éœ€æ±‚
- **JINA**: é€‚ç”¨äºéœ€è¦ç»“æ„åŒ–è¾“å‡ºå’ŒAIä¼˜åŒ–çš„åœºæ™¯

### 2. æ€§èƒ½ä¼˜åŒ–

```python
# å¹¶å‘æ§åˆ¶ï¼Œé¿å…è¿‡è½½
request = WebReadRequest(
    urls=url_list,
    max_concurrent=3,  # æ§åˆ¶å¹¶å‘æ•°
    timeout=30         # è®¾ç½®åˆç†è¶…æ—¶
)

# æ‰¹é‡å¤„ç†ï¼Œæé«˜æ•ˆç‡
batch_size = 10
for i in range(0, len(urls), batch_size):
    batch_urls = urls[i:i+batch_size]
    # å¤„ç†æ‰¹æ¬¡
```

### 3. é”™è¯¯å¤„ç†ç­–ç•¥

```python
async def robust_web_operation(service, request, max_retries=3):
    """å¸¦é‡è¯•æœºåˆ¶çš„Webæ“ä½œ"""
    for attempt in range(max_retries):
        try:
            return await service.search(request)  # æˆ– service.read(request)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            await asyncio.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 4. ç¼“å­˜ç­–ç•¥

```python
from functools import lru_cache
import hashlib

class CachedWebService:
    def __init__(self):
        self.search_service = SearchService()
        self.reader_service = ReaderService()
    
    @lru_cache(maxsize=100)
    async def cached_search(self, query: str, max_results: int = 5):
        """å¸¦ç¼“å­˜çš„æœç´¢"""
        request = WebSearchRequest(query=query, max_results=max_results)
        return await self.search_service.search(request)
```

## ä¾èµ–è¯´æ˜

```python
# æ ¸å¿ƒä¾èµ–
pip install duckduckgo-search  # DuckDuckGoæœç´¢
pip install trafilatura       # å†…å®¹æå–
pip install aiohttp           # HTTPå®¢æˆ·ç«¯ï¼ˆJINA providersï¼‰

# å¯é€‰ä¾èµ–ï¼ˆæ ¹æ®ä½¿ç”¨çš„providerå®‰è£…ï¼‰
pip install beautifulsoup4    # HTMLè§£æå¢å¼º
pip install lxml             # XML/HTMLè§£æå™¨
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **JINA APIå¯†é’¥é—®é¢˜**
   ```python
   # ç¡®ä¿APIå¯†é’¥æ­£ç¡®ä¼ é€’
   config = {"api_key": "jina_xxxxxxxxxxxx"}
   service = SearchService(provider_name="jina", provider_config=config)
   ```

2. **ç½‘ç»œè¶…æ—¶**
   ```python
   # å¢åŠ è¶…æ—¶æ—¶é—´
   request = WebSearchRequest(query="...", timeout=60)
   ```

3. **å¹¶å‘é™åˆ¶**
   ```python
   # å‡å°‘å¹¶å‘æ•°
   request = WebReadRequest(urls=urls, max_concurrent=2)
   ```

4. **å†…å®¹æå–å¤±è´¥**
   ```python
   # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œè®©provideræœ‰æ›´å¤šæ—¶é—´å¤„ç†å¤æ‚é¡µé¢
   request = WebReadRequest(
       urls=url,
       timeout=60,           # å¢åŠ è¶…æ—¶æ—¶é—´
       max_concurrent=1      # é™ä½å¹¶å‘æ•°
   )
   ```

---

**æ›´å¤šä¿¡æ¯è¯·å‚è€ƒï¼š**
- [Agentåç«¯è®¾è®¡æ–‡æ¡£](../../docs/design/agent-backend-zh.md)
- [JINA APIæ–‡æ¡£](https://jina.ai/reader)
- [DuckDuckGo Searchæ–‡æ¡£](https://pypi.org/project/duckduckgo-search/)
- [Trafilaturaæ–‡æ¡£](https://trafilatura.readthedocs.io/) 