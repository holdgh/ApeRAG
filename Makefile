VERSION ?= v0.1.2
VERSION_FILE ?= aperag/version/__init__.py
LLMSERVER_VERSION ?= v0.1.1
BUILDX_PLATFORM ?= linux/amd64
BUILDX_ARGS ?= --sbom=false --provenance=false
REGISTRY ?= registry.cn-hangzhou.aliyuncs.com

.PHONY: version
version:
	@git rev-parse HEAD | cut -c1-7 > commit_id.txt
	@echo "VERSION = '$(VERSION)'" > $(VERSION_FILE)
	@echo "GIT_COMMIT_ID = '$$(cat commit_id.txt)'" >> $(VERSION_FILE)
	@rm commit_id.txt

.PHONY: image

# Create a new builder instance for multi-platform builds
setup-builder:
	@if ! docker buildx inspect multi-platform >/dev/null 2>&1; then \
		docker buildx create --name multi-platform --use --driver docker-container; \
	else \
		docker buildx use multi-platform; \
	fi

# Build and push multi-platform image
image: setup-builder
	docker buildx build -t $(REGISTRY)/apecloud/aperag:$(VERSION) --platform $(BUILDX_PLATFORM) $(BUILDX_ARGS) --push -f ./Dockerfile .
	cd frontend && make PLATFORMS=${BUILDX_PLATFORM} REGISTRY=${REGISTRY} TAG=${VERSION}

# Clean up builder instance
clean-builder:
	docker buildx rm multi-platform

diff:
	@python manage.py diffsettings

makemigration:
	@python manage.py makemigrations

migrate:
	@python manage.py migrate aperag
	@python manage.py migrate

run-redis:
	@echo "Starting redis"
	@docker inspect aperag-redis-dev > /dev/null 2>&1 || docker run -d --name aperag-redis-dev -p 6379:6379 redis:latest
	@docker start aperag-redis-dev

run-postgres:
	@echo "Starting postgres with pgvector extension"
	@docker inspect aperag-postgres-dev > /dev/null 2>&1 || \
		docker run -d --name aperag-postgres-dev \
		-p 5432:5432 \
		-e POSTGRES_PASSWORD=postgres \
		pgvector/pgvector:pg16
	@docker start aperag-postgres-dev
	@echo "Ensuring pgvector extension is enabled"
	@sleep 3
	@docker exec aperag-postgres-dev psql -U postgres -c "CREATE EXTENSION IF NOT EXISTS vector;"
	@echo "Verifying pgvector installation"
	@docker exec aperag-postgres-dev psql -U postgres -c "SELECT extname, extversion FROM pg_extension WHERE extname = 'vector';"

run-qdrant:
	@echo "Starting qdrant"
	@docker inspect aperag-qdrant-dev > /dev/null 2>&1 || docker run -d --name aperag-qdrant-dev -p 6333:6333 qdrant/qdrant
	@docker start aperag-qdrant-dev

run-es:
	@echo "Starting Elasticsearch (development mode)"
	@docker inspect aperag-es-dev > /dev/null 2>&1 || \
	docker run -d \
		--name aperag-es-dev \
		-p 9200:9200 \
		-e discovery.type=single-node \
		-e ES_JAVA_OPTS="-Xms1g -Xmx1g" \
		-e xpack.security.enabled=false \
		-v esdata:/usr/share/elasticsearch/data \
		apecloud/elasticsearch:8.8.2
	@docker start aperag-es-dev || true
	@echo "Checking if IK Analyzer is installed..."
	@docker exec aperag-es-dev bash -c \
		"if [ ! -d plugins/analysis-ik ]; then \
			echo 'Installing IK Analyzer from get.infini.cloud...'; \
			curl -L --output /tmp/analysis-ik.zip https://get.infini.cloud/elasticsearch/analysis-ik/8.8.2; \
			echo 'y' | bin/elasticsearch-plugin install file:///tmp/analysis-ik.zip; \
			echo 'Restarting Elasticsearch to apply changes...'; \
		else \
			echo 'IK Analyzer is already installed.'; \
		fi"
	@docker restart aperag-es-dev > /dev/null
	@echo "Elasticsearch is ready with IK Analyzer!"

run-minio:
	@echo "Starting MinIO"
	@docker inspect aperag-minio-dev > /dev/null 2>&1 || \
	docker run -d --name aperag-minio-dev -p 9000:9000 -p 9001:9001 \
		quay.io/minio/minio server /data --console-address ":9001"
	@docker start aperag-minio-dev > /dev/null

run-db: run-redis run-postgres run-qdrant run-es

connect-metadb:
	@docker exec -it aperag-postgres-dev psql -p 5432 -U postgres

clean:
	@echo "Removing db.sqlite3"
	@/bin/rm -f db.sqlite3
	@echo "Removing container aperag-postgres-dev"
	@docker rm -fv aperag-postgres-dev > /dev/null 2>&1 || true
	@echo "Removing container aperag-redis-dev"
	@docker rm -fv aperag-redis-dev > /dev/null 2>&1 || true
	@echo "Removing container aperag-qdrant-dev"
	@docker rm -fv aperag-qdrant-dev > /dev/null 2>&1 || true
	@echo "Removing container aperag-es-dev"
	@docker rm -fv aperag-es-dev > /dev/null 2>&1 || true

run-frontend:
	cp ./frontend/deploy/env.local.template ./frontend/.env
	cd ./frontend && yarn dev

run-backend: migrate
	python manage.py collectstatic --noinput
	uvicorn config.asgi:application --host 0.0.0.0 --reload --reload-include '*.html'

compose-up: migrate
	docker-compose -f compose.yml up -d

compose-down:
	docker-compose -f compose.yml down

compose-logs:
	docker-compose -f compose.yml logs -f

format:
	uvx ruff check --fix ./aperag ./tests
	uvx ruff format --exit-non-zero-on-format ./aperag ./tests

lint:
	uvx ruff check --no-fix ./aperag
	uvx ruff format --exit-non-zero-on-format --diff ./aperag

static-check:
	uvx mypy ./aperag

test:
	pytest tests/ -v

celery:
	celery -A config.celery worker -B -l INFO

flower:
	celery -A config.celery flower --conf/flowerconfig.py

addlicense:
	@echo "Adding license headers..."
	addlicense -c "ApeCloud, Inc." -y 2025 -l apache \
	  -ignore "**/*.md" \
	  -ignore "**/*.sh" \
	  -ignore "**/*.yml" \
	  -ignore "**/*.yaml" \
	  -ignore "**/*.toml" \
	  -ignore "**/Makefile" \
	  -ignore "**/Dockerfile" \
	  -ignore "**/compose.yml" \
	  -ignore "**/__pycache__/**" \
	  -ignore "**/migrations/**" \
	  -ignore "**/templates/**" \
	  -ignore "aperag/readers/**" \
	  -ignore "aperag/vectorstore/**" \
	  .

.PHONY: merge-openapi
merge-openapi:
	@echo "Merging OpenAPI files..."
	@cd aperag && redocly bundle ./api/openapi.yaml > ./api/openapi.merged.yaml

.PHONY: generate-models
generate-models: merge-openapi
	@echo "Generating Python models from OpenAPI specification..."
	@datamodel-codegen \
		--input aperag/api/openapi.merged.yaml \
		--input-file-type openapi \
		--output aperag/schema/view_models.py \
		--output-model-type pydantic.BaseModel \
		--target-python-version 3.11 \
		--use-standard-collections \
		--use-schema-description \
		--enum-field-as-literal all
	@rm aperag/api/openapi.merged.yaml
	@echo "Models generated successfully in aperag/schema directory"

.PHONY: generate_model_configs
generate_model_configs:
	python ./scripts/generate_model_configs.py

.PHONY: generate-frontend-sdk
generate-frontend-sdk:
	cd ./frontend && yarn api:build

.PHONY: install-uv venv install dev

# Basic tools
install-uv: ## Install uv package manager.
	@if [ -z "$$(which uv)" ]; then \
		echo "Installing uv..."; \
		pip install uv; \
	fi

# Regular users: just want to run the project locally
venv: install-uv ## Create virtual environment if needed.
	@if [ ! -d ".venv" ]; then \
		echo "Creating virtual environment..."; \
		uv venv -p 3.11; \
	fi

install: venv ## Install dependencies for running the project.
	@echo "Installing Python dependencies..."
	uv sync --all-groups --all-extras

# Developers: need code generation and other dev tools
dev: install-uv ## Install development tools for code generation.
	@if [ -z "$$(which redocly)" ]; then \
		echo "Installing redocly..."; \
		npm install @redocly/cli -g; \
	fi
	@if [ -z "$$(which openapi-generator-cli)" ]; then \
		echo "Installing openapi-generator-cli..."; \
		npm install @openapitools/openapi-generator-cli -g; \
	fi
	@if [ -z "$$(which datamodel-codegen)" ]; then \
		echo "Installing datamodel-code-generator..."; \
		uv tool install datamodel-code-generator; \
	fi