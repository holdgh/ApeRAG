# LLM_MODEL=gptj-6b
LLM_MODEL=vicuna-13b
MODEL_SERVER=http://47.96.65.19:8000
LIMIT_MODEL_CONCURRENCY=5
MAX_POSITION_EMBEDDINGS=4096
QUANTIZE_QLORA=True


#*******************************************************************#
# **    PROXY_SERVER (openai interface | chatGPT proxy service), use chatGPT as your LLM.
# ** if your server can visit openai, please set PROXY_SERVER_URL=https://api.openai.com/v1/chat/completions
# ** else if you have a chatgpt proxy server, you can set PROXY_SERVER_URL={your-proxy-serverip:port/xxx}
#*******************************************************************#
PROXY_API_KEY=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
#PROXY_API_KEY=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
PROXY_SERVER_URL=http://20.112.37.62:9000/v1/chat/completions

# MetaDB
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_DB=kubechat
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin


# Auth0
AUTH_ENABLED=True
AUTH0_DOMAIN=kubechat.jp.auth0.com
AUTH0_CLIENT_ID=G6RuQZZNaDorHGUEOv7Mgq1COqfryTB2


# Redis
MEMORY_REDIS_URL=redis://127.0.0.1:6379/1


# Logging
DJANGO_LOG_LEVEL=INFO


# Celery
CELERY_BROKER_URL=redis://127.0.0.1:6379/0
CELERY_FLOWER_USER=admin
CELERY_FLOWER_PASSWORD=admin

# Vector DB
VECTOR_DB_TYPE=qdrant
VECTOR_DB_CONTEXT={"url":"http://127.0.0.1", "port":6333, "distance":"Cosine", "timeout": 1000}
